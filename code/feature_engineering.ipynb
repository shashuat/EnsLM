{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1778619, 6), (443811, 5))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = 'final_data/train_df.pkl'\n",
    "train_df = pd.read_pickle(train_path)\n",
    "\n",
    "test_path = 'final_data/test_df.pkl'\n",
    "test_df = pd.read_pickle(test_path)\n",
    "\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_time_series_features(train_df, test_df):\n",
    "    # Combine train and test data\n",
    "    train_df['is_train'] = 1\n",
    "    test_df['is_train'] = 0\n",
    "    combined_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "    \n",
    "    # Create features grouped by MatchID and PeriodID\n",
    "    features = []\n",
    "    \n",
    "    # 1. Tweet count features\n",
    "    tweet_counts = combined_df.groupby(['MatchID', 'PeriodID', 'ID']).size().reset_index(name='tweet_count')\n",
    "    \n",
    "    # 2. Rolling statistics for tweet counts\n",
    "    tweet_counts['rolling_mean_tweets'] = tweet_counts.groupby('MatchID')['tweet_count'].transform(\n",
    "        lambda x: x.rolling(window=3, min_periods=1).mean()\n",
    "    )\n",
    "    tweet_counts['rolling_std_tweets'] = tweet_counts.groupby('MatchID')['tweet_count'].transform(\n",
    "        lambda x: x.rolling(window=3, min_periods=1).std()\n",
    "    )\n",
    "    \n",
    "    # 3. Relative tweet frequency within match\n",
    "    match_totals = tweet_counts.groupby('MatchID')['tweet_count'].transform('sum')\n",
    "    tweet_counts['relative_frequency'] = tweet_counts['tweet_count'] / match_totals\n",
    "    \n",
    "    # 4. Momentum features (change from previous period)\n",
    "    tweet_counts['tweet_momentum'] = tweet_counts.groupby('MatchID')['tweet_count'].transform(\n",
    "        lambda x: x.pct_change().fillna(0)\n",
    "    )\n",
    "    \n",
    "    # 5. Percentile rank within match\n",
    "    tweet_counts['period_percentile'] = tweet_counts.groupby('MatchID')['tweet_count'].transform(\n",
    "        lambda x: x.rank(pct=True)\n",
    "    )\n",
    "    \n",
    "    # Merge features back with IDs\n",
    "    final_features = tweet_counts[['ID', 'MatchID', 'PeriodID', 'tweet_count', 'rolling_mean_tweets',\n",
    "                                 'rolling_std_tweets', 'relative_frequency', 'tweet_momentum',\n",
    "                                 'period_percentile']]\n",
    "    \n",
    "    # Split back into train and test\n",
    "    train_features = final_features.merge(\n",
    "        train_df[['MatchID', 'PeriodID', 'EventType']].drop_duplicates(),\n",
    "        on=['MatchID', 'PeriodID'],\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    test_features = final_features.merge(\n",
    "        test_df[['MatchID', 'PeriodID']].drop_duplicates(),\n",
    "        on=['MatchID', 'PeriodID'],\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    return train_features, test_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train, processed_test = create_time_series_features(train_df, test_df)\n",
    "\n",
    "processed_train.fillna(0, inplace=True)\n",
    "processed_test.fillna(0, inplace=True)\n",
    "\n",
    "processed_train.to_csv('final_features/time_series/train_time_features.csv', index=False)\n",
    "processed_test.to_csv('final_features/time_series/test_time_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>rolling_mean_tweets</th>\n",
       "      <th>rolling_std_tweets</th>\n",
       "      <th>relative_frequency</th>\n",
       "      <th>tweet_momentum</th>\n",
       "      <th>period_percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6_0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>361</td>\n",
       "      <td>361.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6_1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>382</td>\n",
       "      <td>371.500000</td>\n",
       "      <td>14.849242</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>0.058172</td>\n",
       "      <td>0.357692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6_2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>384</td>\n",
       "      <td>375.666667</td>\n",
       "      <td>12.741010</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0.369231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6_3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>480</td>\n",
       "      <td>415.333333</td>\n",
       "      <td>56.011903</td>\n",
       "      <td>0.005141</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.484615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6_4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>653</td>\n",
       "      <td>505.666667</td>\n",
       "      <td>136.324368</td>\n",
       "      <td>0.006994</td>\n",
       "      <td>0.360417</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>16_125</td>\n",
       "      <td>16</td>\n",
       "      <td>125</td>\n",
       "      <td>413</td>\n",
       "      <td>490.333333</td>\n",
       "      <td>78.008547</td>\n",
       "      <td>0.012307</td>\n",
       "      <td>-0.155419</td>\n",
       "      <td>0.884615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>16_126</td>\n",
       "      <td>16</td>\n",
       "      <td>126</td>\n",
       "      <td>385</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>53.814496</td>\n",
       "      <td>0.011473</td>\n",
       "      <td>-0.067797</td>\n",
       "      <td>0.869231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>16_127</td>\n",
       "      <td>16</td>\n",
       "      <td>127</td>\n",
       "      <td>373</td>\n",
       "      <td>390.333333</td>\n",
       "      <td>20.526406</td>\n",
       "      <td>0.011115</td>\n",
       "      <td>-0.031169</td>\n",
       "      <td>0.853846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>16_128</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>333</td>\n",
       "      <td>363.666667</td>\n",
       "      <td>27.227437</td>\n",
       "      <td>0.009923</td>\n",
       "      <td>-0.107239</td>\n",
       "      <td>0.819231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>16_129</td>\n",
       "      <td>16</td>\n",
       "      <td>129</td>\n",
       "      <td>294</td>\n",
       "      <td>333.333333</td>\n",
       "      <td>39.501055</td>\n",
       "      <td>0.008761</td>\n",
       "      <td>-0.117117</td>\n",
       "      <td>0.757692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  MatchID  PeriodID  tweet_count  rolling_mean_tweets  \\\n",
       "0       6_0        6         0          361           361.000000   \n",
       "1       6_1        6         1          382           371.500000   \n",
       "2       6_2        6         2          384           375.666667   \n",
       "3       6_3        6         3          480           415.333333   \n",
       "4       6_4        6         4          653           505.666667   \n",
       "..      ...      ...       ...          ...                  ...   \n",
       "511  16_125       16       125          413           490.333333   \n",
       "512  16_126       16       126          385           429.000000   \n",
       "513  16_127       16       127          373           390.333333   \n",
       "514  16_128       16       128          333           363.666667   \n",
       "515  16_129       16       129          294           333.333333   \n",
       "\n",
       "     rolling_std_tweets  relative_frequency  tweet_momentum  period_percentile  \n",
       "0              0.000000            0.003867        0.000000           0.323077  \n",
       "1             14.849242            0.004092        0.058172           0.357692  \n",
       "2             12.741010            0.004113        0.005236           0.369231  \n",
       "3             56.011903            0.005141        0.250000           0.484615  \n",
       "4            136.324368            0.006994        0.360417           0.615385  \n",
       "..                  ...                 ...             ...                ...  \n",
       "511           78.008547            0.012307       -0.155419           0.884615  \n",
       "512           53.814496            0.011473       -0.067797           0.869231  \n",
       "513           20.526406            0.011115       -0.031169           0.853846  \n",
       "514           27.227437            0.009923       -0.107239           0.819231  \n",
       "515           39.501055            0.008761       -0.117117           0.757692  \n",
       "\n",
       "[516 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
