{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/Users/shash/github/sms/data/gemini_embeds/test_embeds.csv')\n",
    "train1_df = pd.read_csv('/Users/shash/github/sms/data/gemini_embeds/train_embeds.csv')\n",
    "val_df = pd.read_csv('/Users/shash/github/sms/data/gemini_embeds/val_embeds.csv')\n",
    "\n",
    "train_df = pd.concat([train1_df, val_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_embedding_string(embedding_str):\n",
    "    \"\"\"Parse embedding string to numpy array\"\"\"\n",
    "    if isinstance(embedding_str, str):\n",
    "        # Remove brackets and split by comma\n",
    "        values = embedding_str.strip('[]').split(',')\n",
    "        # Convert to floats\n",
    "        return np.array([float(x.strip()) for x in values])\n",
    "    return np.array(embedding_str)\n",
    "\n",
    "def preprocess_data(df, is_training=True):\n",
    "    \"\"\"\n",
    "    Preprocess the data by converting embeddings to numpy arrays\n",
    "    \"\"\"\n",
    "    # Convert embeddings to numpy arrays\n",
    "    X = np.array([parse_embedding_string(emb) for emb in df['Embeddings']])\n",
    "    \n",
    "    if is_training and 'EventType' in df.columns:\n",
    "        y = df['EventType'].values\n",
    "    else:\n",
    "        y = None\n",
    "        \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attention_model(embedding_dim):\n",
    "    \"\"\"Create attention model for Gemini embeddings.\"\"\"\n",
    "    # Input layer\n",
    "    inputs = layers.Input(shape=(embedding_dim,))\n",
    "    \n",
    "    # Project input to attention space\n",
    "    attention = layers.Dense(embedding_dim, use_bias=False)(inputs)\n",
    "    attention_weights = layers.Activation('softmax')(attention)\n",
    "    \n",
    "    # Apply attention weights\n",
    "    attended = layers.Multiply()([inputs, attention_weights])\n",
    "    \n",
    "    # Dense layers for classification\n",
    "    x = layers.Dense(2048, activation='relu')(attended)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "def get_callbacks(model_prefix):\n",
    "    \"\"\"Create callbacks for training.\"\"\"\n",
    "    os.makedirs('models/gemini_attention', exist_ok=True)\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_accuracy',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            f'models/gemini_attention/{model_prefix}_best_model.keras',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ensemble_model(train_df, n_splits=5, epochs=50, batch_size=32):\n",
    "    \"\"\"Train multiple models using cross-validation based on MatchID.\"\"\"\n",
    "    # Get unique MatchIDs\n",
    "    unique_matches = train_df['MatchID'].unique()\n",
    "    \n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Lists to store models and histories\n",
    "    models = []\n",
    "    histories = []\n",
    "    fold_metrics = []\n",
    "    \n",
    "    # Get embedding dimension from first sample\n",
    "    first_embedding = parse_embedding_string(train_df['Embeddings'].iloc[0])\n",
    "    embedding_dim = len(first_embedding)\n",
    "    print(f\"Embedding dimension: {embedding_dim}\")\n",
    "    \n",
    "    # Train models\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(unique_matches)):\n",
    "        print(f\"\\nTraining fold {fold + 1}/{n_splits}\")\n",
    "        \n",
    "        # Split data based on MatchID\n",
    "        train_matches = unique_matches[train_idx]\n",
    "        val_matches = unique_matches[val_idx]\n",
    "        \n",
    "        train_data = train_df[train_df['MatchID'].isin(train_matches)]\n",
    "        val_data = train_df[train_df['MatchID'].isin(val_matches)]\n",
    "        \n",
    "        # Preprocess data\n",
    "        X_train, y_train = preprocess_data(train_data)\n",
    "        X_val, y_val = preprocess_data(val_data)\n",
    "        \n",
    "        print(f\"Training data shape: {X_train.shape}\")\n",
    "        print(f\"Validation data shape: {X_val.shape}\")\n",
    "        \n",
    "        # Create and compile model\n",
    "        model = create_attention_model(embedding_dim)\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy', tf.keras.metrics.AUC()]\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=get_callbacks(f'fold_{fold}'),\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_metrics = model.evaluate(X_val, y_val, verbose=0)\n",
    "        fold_metrics.append({\n",
    "            'val_loss': val_metrics[0],\n",
    "            'val_accuracy': val_metrics[1],\n",
    "            'val_auc': val_metrics[2]\n",
    "        })\n",
    "        \n",
    "        models.append(model)\n",
    "        histories.append(history.history)\n",
    "    \n",
    "    return models, histories, fold_metrics\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def save_fold_predictions(models, data_df, output_path, is_train=True):\n",
    "    \"\"\"\n",
    "    Generate and save predictions from each fold model.\n",
    "    \n",
    "    Args:\n",
    "        models: List of trained attention models\n",
    "        data_df: DataFrame with ID, Embeddings, and MatchID columns\n",
    "        output_path: Path to save the predictions\n",
    "        is_train: Boolean indicating if this is training data\n",
    "    \"\"\"\n",
    "    # Group data by period\n",
    "    grouped_data = data_df.groupby('ID').agg({\n",
    "        'Embeddings': 'first',  # Take first embedding since they should be the same per ID\n",
    "        'MatchID': 'first',\n",
    "        'PeriodID': 'first'\n",
    "    })\n",
    "    \n",
    "    if is_train and 'EventType' in data_df.columns:\n",
    "        grouped_data['EventType'] = data_df.groupby('ID')['EventType'].first()\n",
    "    \n",
    "    grouped_data = grouped_data.reset_index()\n",
    "    \n",
    "    # Get predictions from each model\n",
    "    all_preds = pd.DataFrame({'ID': grouped_data['ID']})\n",
    "    all_preds['PeriodID'] = grouped_data['PeriodID'].astype(int)\n",
    "    \n",
    "    # Preprocess data once for all models\n",
    "    X, _ = preprocess_data(grouped_data, is_training=False)\n",
    "    \n",
    "    # Get predictions from each model\n",
    "    for i, model in enumerate(models):\n",
    "        preds = model.predict(X)\n",
    "        all_preds[f'model_{i}_pred'] = preds.flatten()\n",
    "    \n",
    "    # Add true labels for training data\n",
    "    if is_train and 'EventType' in data_df.columns:\n",
    "        all_preds['EventType'] = grouped_data['EventType']\n",
    "    \n",
    "    # Calculate ensemble predictions\n",
    "    pred_columns = [col for col in all_preds.columns if col.endswith('_pred')]\n",
    "    all_preds['ensemble_pred'] = all_preds[pred_columns].mean(axis=1)\n",
    "    \n",
    "    # Save predictions\n",
    "    all_preds.to_csv(output_path, index=False)\n",
    "    print(f\"Predictions saved to {output_path}\")\n",
    "    \n",
    "    return all_preds\n",
    "\n",
    "def predict_with_ensemble(models, test_df):\n",
    "    \"\"\"Make predictions using the ensemble of models.\"\"\"\n",
    "    # Preprocess test data\n",
    "    X_test, _ = preprocess_data(test_df, is_training=False)\n",
    "    \n",
    "    # Get predictions from each model\n",
    "    predictions = []\n",
    "    for model in models:\n",
    "        pred = model.predict(X_test)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    # Average predictions\n",
    "    ensemble_pred = np.mean(predictions, axis=0)\n",
    "    return ensemble_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 768\n",
      "\n",
      "Training fold 1/5\n",
      "Training data shape: (1560, 768)\n",
      "Validation data shape: (487, 768)\n",
      "Epoch 1/50\n",
      "\u001b[1m44/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5235 - auc: 0.5257 - loss: 0.8750\n",
      "Epoch 1: val_accuracy improved from -inf to 0.56879, saving model to models/gemini_attention/fold_0_best_model.keras\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5243 - auc: 0.5284 - loss: 0.8734 - val_accuracy: 0.5688 - val_auc: 0.5000 - val_loss: 0.6891 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m45/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5902 - auc: 0.6288 - loss: 0.7712\n",
      "Epoch 2: val_accuracy did not improve from 0.56879\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5906 - auc: 0.6291 - loss: 0.7699 - val_accuracy: 0.5688 - val_auc: 0.5000 - val_loss: 0.6907 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6036 - auc: 0.6497 - loss: 0.7074\n",
      "Epoch 3: val_accuracy did not improve from 0.56879\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6039 - auc: 0.6499 - loss: 0.7074 - val_accuracy: 0.4312 - val_auc: 0.5000 - val_loss: 0.6956 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m48/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6457 - auc: 0.6906 - loss: 0.6816\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.56879\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6457 - auc: 0.6908 - loss: 0.6813 - val_accuracy: 0.4312 - val_auc: 0.5897 - val_loss: 0.7105 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m46/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6669 - auc: 0.7294 - loss: 0.6330\n",
      "Epoch 5: val_accuracy did not improve from 0.56879\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6664 - auc: 0.7287 - loss: 0.6339 - val_accuracy: 0.4312 - val_auc: 0.6181 - val_loss: 0.7166 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m48/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7127 - auc: 0.7662 - loss: 0.5939\n",
      "Epoch 6: val_accuracy did not improve from 0.56879\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7129 - auc: 0.7664 - loss: 0.5935 - val_accuracy: 0.4312 - val_auc: 0.6664 - val_loss: 0.7166 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m48/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7021 - auc: 0.7652 - loss: 0.5973\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.56879\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7018 - auc: 0.7650 - loss: 0.5978 - val_accuracy: 0.4312 - val_auc: 0.6577 - val_loss: 0.7113 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7009 - auc: 0.7710 - loss: 0.5823\n",
      "Epoch 8: val_accuracy did not improve from 0.56879\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7008 - auc: 0.7709 - loss: 0.5825 - val_accuracy: 0.4312 - val_auc: 0.6605 - val_loss: 0.7064 - learning_rate: 2.5000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m43/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7277 - auc: 0.7696 - loss: 0.5832\n",
      "Epoch 9: val_accuracy did not improve from 0.56879\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7272 - auc: 0.7708 - loss: 0.5824 - val_accuracy: 0.4908 - val_auc: 0.6590 - val_loss: 0.6990 - learning_rate: 2.5000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m46/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7148 - auc: 0.7915 - loss: 0.5545\n",
      "Epoch 10: val_accuracy improved from 0.56879 to 0.57290, saving model to models/gemini_attention/fold_0_best_model.keras\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7138 - auc: 0.7910 - loss: 0.5555 - val_accuracy: 0.5729 - val_auc: 0.6663 - val_loss: 0.6843 - learning_rate: 2.5000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m46/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7100 - auc: 0.7906 - loss: 0.5657\n",
      "Epoch 11: val_accuracy did not improve from 0.57290\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7101 - auc: 0.7901 - loss: 0.5660 - val_accuracy: 0.5667 - val_auc: 0.6705 - val_loss: 0.6812 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m45/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7212 - auc: 0.8053 - loss: 0.5415\n",
      "Epoch 12: val_accuracy improved from 0.57290 to 0.58111, saving model to models/gemini_attention/fold_0_best_model.keras\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7221 - auc: 0.8052 - loss: 0.5421 - val_accuracy: 0.5811 - val_auc: 0.6642 - val_loss: 0.6735 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m47/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7294 - auc: 0.8084 - loss: 0.5377\n",
      "Epoch 13: val_accuracy did not improve from 0.58111\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7297 - auc: 0.8083 - loss: 0.5382 - val_accuracy: 0.5749 - val_auc: 0.6640 - val_loss: 0.6898 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m44/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7127 - auc: 0.7797 - loss: 0.5906\n",
      "Epoch 14: val_accuracy did not improve from 0.58111\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7145 - auc: 0.7813 - loss: 0.5883 - val_accuracy: 0.5791 - val_auc: 0.6612 - val_loss: 0.6442 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m47/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7246 - auc: 0.8085 - loss: 0.5382\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 15: val_accuracy did not improve from 0.58111\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7247 - auc: 0.8081 - loss: 0.5390 - val_accuracy: 0.5811 - val_auc: 0.6601 - val_loss: 0.7144 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m47/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7277 - auc: 0.8045 - loss: 0.5433\n",
      "Epoch 16: val_accuracy did not improve from 0.58111\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7277 - auc: 0.8045 - loss: 0.5433 - val_accuracy: 0.5770 - val_auc: 0.6614 - val_loss: 0.7686 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7457 - auc: 0.8258 - loss: 0.5209\n",
      "Epoch 17: val_accuracy improved from 0.58111 to 0.58316, saving model to models/gemini_attention/fold_0_best_model.keras\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7458 - auc: 0.8256 - loss: 0.5213 - val_accuracy: 0.5832 - val_auc: 0.6620 - val_loss: 0.7875 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7452 - auc: 0.7996 - loss: 0.5630\n",
      "Epoch 18: val_accuracy improved from 0.58316 to 0.59138, saving model to models/gemini_attention/fold_0_best_model.keras\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7454 - auc: 0.7998 - loss: 0.5626 - val_accuracy: 0.5914 - val_auc: 0.6655 - val_loss: 0.7558 - learning_rate: 1.2500e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m47/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7453 - auc: 0.8043 - loss: 0.5481\n",
      "Epoch 19: val_accuracy did not improve from 0.59138\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7461 - auc: 0.8055 - loss: 0.5464 - val_accuracy: 0.5852 - val_auc: 0.6638 - val_loss: 0.8007 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m47/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7365 - auc: 0.8082 - loss: 0.5384\n",
      "Epoch 20: val_accuracy did not improve from 0.59138\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7375 - auc: 0.8089 - loss: 0.5377 - val_accuracy: 0.5770 - val_auc: 0.6625 - val_loss: 0.8219 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m45/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7504 - auc: 0.8215 - loss: 0.5254\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 0.59138\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7493 - auc: 0.8208 - loss: 0.5263 - val_accuracy: 0.5832 - val_auc: 0.6649 - val_loss: 0.8056 - learning_rate: 1.2500e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m45/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7430 - auc: 0.8132 - loss: 0.5318\n",
      "Epoch 22: val_accuracy did not improve from 0.59138\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7436 - auc: 0.8141 - loss: 0.5308 - val_accuracy: 0.5770 - val_auc: 0.6649 - val_loss: 0.8331 - learning_rate: 6.2500e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m44/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7690 - auc: 0.8398 - loss: 0.4984\n",
      "Epoch 23: val_accuracy did not improve from 0.59138\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7669 - auc: 0.8378 - loss: 0.5013 - val_accuracy: 0.5914 - val_auc: 0.6648 - val_loss: 0.8098 - learning_rate: 6.2500e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m47/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7528 - auc: 0.8338 - loss: 0.5131\n",
      "Epoch 24: val_accuracy improved from 0.59138 to 0.59754, saving model to models/gemini_attention/fold_0_best_model.keras\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7525 - auc: 0.8332 - loss: 0.5137 - val_accuracy: 0.5975 - val_auc: 0.6638 - val_loss: 0.7995 - learning_rate: 6.2500e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m46/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7468 - auc: 0.8036 - loss: 0.5556\n",
      "Epoch 25: val_accuracy did not improve from 0.59754\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7472 - auc: 0.8056 - loss: 0.5527 - val_accuracy: 0.5934 - val_auc: 0.6655 - val_loss: 0.8166 - learning_rate: 6.2500e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m45/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7508 - auc: 0.8066 - loss: 0.5479\n",
      "Epoch 26: val_accuracy did not improve from 0.59754\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7514 - auc: 0.8078 - loss: 0.5462 - val_accuracy: 0.5914 - val_auc: 0.6650 - val_loss: 0.7959 - learning_rate: 6.2500e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m47/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7621 - auc: 0.8239 - loss: 0.5296\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 27: val_accuracy did not improve from 0.59754\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7616 - auc: 0.8241 - loss: 0.5288 - val_accuracy: 0.5934 - val_auc: 0.6642 - val_loss: 0.7942 - learning_rate: 6.2500e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m47/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7455 - auc: 0.8278 - loss: 0.5308\n",
      "Epoch 28: val_accuracy did not improve from 0.59754\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7465 - auc: 0.8286 - loss: 0.5289 - val_accuracy: 0.5934 - val_auc: 0.6642 - val_loss: 0.8091 - learning_rate: 3.1250e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m48/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7532 - auc: 0.8320 - loss: 0.5124\n",
      "Epoch 29: val_accuracy did not improve from 0.59754\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7536 - auc: 0.8321 - loss: 0.5122 - val_accuracy: 0.5955 - val_auc: 0.6629 - val_loss: 0.8094 - learning_rate: 3.1250e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m46/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7596 - auc: 0.8414 - loss: 0.4989\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 30: val_accuracy did not improve from 0.59754\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7598 - auc: 0.8406 - loss: 0.4999 - val_accuracy: 0.5975 - val_auc: 0.6633 - val_loss: 0.8033 - learning_rate: 3.1250e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m45/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7674 - auc: 0.8488 - loss: 0.4903\n",
      "Epoch 31: val_accuracy did not improve from 0.59754\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7655 - auc: 0.8465 - loss: 0.4930 - val_accuracy: 0.5955 - val_auc: 0.6637 - val_loss: 0.8218 - learning_rate: 1.5625e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m47/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7489 - auc: 0.8266 - loss: 0.5180\n",
      "Epoch 32: val_accuracy did not improve from 0.59754\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7494 - auc: 0.8268 - loss: 0.5177 - val_accuracy: 0.5955 - val_auc: 0.6641 - val_loss: 0.8196 - learning_rate: 1.5625e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m47/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7817 - auc: 0.8423 - loss: 0.4946\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 33: val_accuracy did not improve from 0.59754\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7808 - auc: 0.8415 - loss: 0.4958 - val_accuracy: 0.5975 - val_auc: 0.6644 - val_loss: 0.8190 - learning_rate: 1.5625e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m46/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7598 - auc: 0.8280 - loss: 0.5179\n",
      "Epoch 34: val_accuracy did not improve from 0.59754\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7594 - auc: 0.8276 - loss: 0.5182 - val_accuracy: 0.5975 - val_auc: 0.6648 - val_loss: 0.8159 - learning_rate: 7.8125e-06\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "\n",
      "Training fold 2/5\n",
      "Training data shape: (1657, 768)\n",
      "Validation data shape: (390, 768)\n",
      "Epoch 1/50\n",
      "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4900 - auc_1: 0.4873 - loss: 0.8805\n",
      "Epoch 1: val_accuracy improved from -inf to 0.42564, saving model to models/gemini_attention/fold_1_best_model.keras\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4911 - auc_1: 0.4888 - loss: 0.8790 - val_accuracy: 0.4256 - val_auc_1: 0.5000 - val_loss: 0.7125 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5405 - auc_1: 0.5387 - loss: 0.7926\n",
      "Epoch 2: val_accuracy did not improve from 0.42564\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5420 - auc_1: 0.5415 - loss: 0.7899 - val_accuracy: 0.4256 - val_auc_1: 0.5000 - val_loss: 0.7183 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5886 - auc_1: 0.6080 - loss: 0.7170\n",
      "Epoch 3: val_accuracy did not improve from 0.42564\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5885 - auc_1: 0.6082 - loss: 0.7169 - val_accuracy: 0.4256 - val_auc_1: 0.5000 - val_loss: 0.7244 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6072 - auc_1: 0.6563 - loss: 0.6786\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.42564\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6086 - auc_1: 0.6572 - loss: 0.6782 - val_accuracy: 0.4256 - val_auc_1: 0.6576 - val_loss: 0.7097 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6457 - auc_1: 0.6991 - loss: 0.6525\n",
      "Epoch 5: val_accuracy did not improve from 0.42564\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6455 - auc_1: 0.6991 - loss: 0.6518 - val_accuracy: 0.4256 - val_auc_1: 0.7598 - val_loss: 0.7037 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6511 - auc_1: 0.7068 - loss: 0.6326\n",
      "Epoch 6: val_accuracy did not improve from 0.42564\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6523 - auc_1: 0.7077 - loss: 0.6320 - val_accuracy: 0.4256 - val_auc_1: 0.7806 - val_loss: 0.6967 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6732 - auc_1: 0.7378 - loss: 0.6124\n",
      "Epoch 7: val_accuracy improved from 0.42564 to 0.53333, saving model to models/gemini_attention/fold_1_best_model.keras\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6732 - auc_1: 0.7378 - loss: 0.6124 - val_accuracy: 0.5333 - val_auc_1: 0.7783 - val_loss: 0.6829 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6962 - auc_1: 0.7531 - loss: 0.5927\n",
      "Epoch 8: val_accuracy improved from 0.53333 to 0.55641, saving model to models/gemini_attention/fold_1_best_model.keras\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6952 - auc_1: 0.7523 - loss: 0.5935 - val_accuracy: 0.5564 - val_auc_1: 0.7946 - val_loss: 0.6753 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6948 - auc_1: 0.7602 - loss: 0.5841 \n",
      "Epoch 9: val_accuracy did not improve from 0.55641\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6938 - auc_1: 0.7588 - loss: 0.5857 - val_accuracy: 0.4487 - val_auc_1: 0.7979 - val_loss: 0.6768 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6834 - auc_1: 0.7427 - loss: 0.6148\n",
      "Epoch 10: val_accuracy did not improve from 0.55641\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6838 - auc_1: 0.7434 - loss: 0.6138 - val_accuracy: 0.4923 - val_auc_1: 0.7948 - val_loss: 0.6706 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6566 - auc_1: 0.7367 - loss: 0.6097\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 0.55641\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6581 - auc_1: 0.7378 - loss: 0.6085 - val_accuracy: 0.5333 - val_auc_1: 0.8020 - val_loss: 0.6513 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7001 - auc_1: 0.7776 - loss: 0.5603\n",
      "Epoch 12: val_accuracy did not improve from 0.55641\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7000 - auc_1: 0.7776 - loss: 0.5604 - val_accuracy: 0.5128 - val_auc_1: 0.8059 - val_loss: 0.6609 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m46/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7171 - auc_1: 0.7909 - loss: 0.5464\n",
      "Epoch 13: val_accuracy improved from 0.55641 to 0.69231, saving model to models/gemini_attention/fold_1_best_model.keras\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7164 - auc_1: 0.7895 - loss: 0.5493 - val_accuracy: 0.6923 - val_auc_1: 0.8066 - val_loss: 0.5893 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7405 - auc_1: 0.8060 - loss: 0.5366\n",
      "Epoch 14: val_accuracy did not improve from 0.69231\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7394 - auc_1: 0.8050 - loss: 0.5378 - val_accuracy: 0.6590 - val_auc_1: 0.8042 - val_loss: 0.5868 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7218 - auc_1: 0.7983 - loss: 0.5402\n",
      "Epoch 15: val_accuracy improved from 0.69231 to 0.72308, saving model to models/gemini_attention/fold_1_best_model.keras\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7216 - auc_1: 0.7979 - loss: 0.5407 - val_accuracy: 0.7231 - val_auc_1: 0.8052 - val_loss: 0.5484 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7127 - auc_1: 0.7870 - loss: 0.5571\n",
      "Epoch 16: val_accuracy improved from 0.72308 to 0.75128, saving model to models/gemini_attention/fold_1_best_model.keras\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7129 - auc_1: 0.7871 - loss: 0.5568 - val_accuracy: 0.7513 - val_auc_1: 0.8071 - val_loss: 0.5281 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7396 - auc_1: 0.8003 - loss: 0.5410\n",
      "Epoch 17: val_accuracy did not improve from 0.75128\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7389 - auc_1: 0.8006 - loss: 0.5407 - val_accuracy: 0.7513 - val_auc_1: 0.8062 - val_loss: 0.5246 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7379 - auc_1: 0.8053 - loss: 0.5361\n",
      "Epoch 18: val_accuracy did not improve from 0.75128\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7375 - auc_1: 0.8051 - loss: 0.5364 - val_accuracy: 0.7359 - val_auc_1: 0.8100 - val_loss: 0.5351 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7489 - auc_1: 0.8161 - loss: 0.5219\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 19: val_accuracy did not improve from 0.75128\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7486 - auc_1: 0.8161 - loss: 0.5219 - val_accuracy: 0.7077 - val_auc_1: 0.8113 - val_loss: 0.5691 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7380 - auc_1: 0.8130 - loss: 0.5343\n",
      "Epoch 20: val_accuracy did not improve from 0.75128\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7377 - auc_1: 0.8129 - loss: 0.5343 - val_accuracy: 0.7026 - val_auc_1: 0.8113 - val_loss: 0.5841 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m46/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7634 - auc_1: 0.8315 - loss: 0.5064\n",
      "Epoch 21: val_accuracy did not improve from 0.75128\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7611 - auc_1: 0.8299 - loss: 0.5086 - val_accuracy: 0.7000 - val_auc_1: 0.8109 - val_loss: 0.5872 - learning_rate: 1.2500e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m46/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7357 - auc_1: 0.8136 - loss: 0.5282\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 22: val_accuracy did not improve from 0.75128\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7364 - auc_1: 0.8137 - loss: 0.5276 - val_accuracy: 0.7128 - val_auc_1: 0.8108 - val_loss: 0.5625 - learning_rate: 1.2500e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7337 - auc_1: 0.8164 - loss: 0.5213\n",
      "Epoch 23: val_accuracy did not improve from 0.75128\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7351 - auc_1: 0.8173 - loss: 0.5204 - val_accuracy: 0.7256 - val_auc_1: 0.8109 - val_loss: 0.5468 - learning_rate: 6.2500e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7177 - auc_1: 0.7979 - loss: 0.5473\n",
      "Epoch 24: val_accuracy did not improve from 0.75128\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7189 - auc_1: 0.7990 - loss: 0.5458 - val_accuracy: 0.7359 - val_auc_1: 0.8094 - val_loss: 0.5346 - learning_rate: 6.2500e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7552 - auc_1: 0.8306 - loss: 0.5041\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 25: val_accuracy did not improve from 0.75128\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7546 - auc_1: 0.8300 - loss: 0.5050 - val_accuracy: 0.7359 - val_auc_1: 0.8103 - val_loss: 0.5402 - learning_rate: 6.2500e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7319 - auc_1: 0.8003 - loss: 0.5423\n",
      "Epoch 26: val_accuracy did not improve from 0.75128\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7324 - auc_1: 0.8010 - loss: 0.5415 - val_accuracy: 0.7359 - val_auc_1: 0.8105 - val_loss: 0.5354 - learning_rate: 3.1250e-05\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "\n",
      "Training fold 3/5\n",
      "Training data shape: (1657, 768)\n",
      "Validation data shape: (390, 768)\n",
      "Epoch 1/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5240 - auc_2: 0.5368 - loss: 0.8334\n",
      "Epoch 1: val_accuracy improved from -inf to 0.57692, saving model to models/gemini_attention/fold_2_best_model.keras\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5244 - auc_2: 0.5373 - loss: 0.8330 - val_accuracy: 0.5769 - val_auc_2: 0.5000 - val_loss: 0.6907 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5588 - auc_2: 0.5901 - loss: 0.7595\n",
      "Epoch 2: val_accuracy did not improve from 0.57692\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5587 - auc_2: 0.5901 - loss: 0.7594 - val_accuracy: 0.5769 - val_auc_2: 0.5000 - val_loss: 0.6878 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m46/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5848 - auc_2: 0.6244 - loss: 0.7152\n",
      "Epoch 3: val_accuracy did not improve from 0.57692\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5890 - auc_2: 0.6288 - loss: 0.7117 - val_accuracy: 0.4231 - val_auc_2: 0.6063 - val_loss: 0.6933 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m46/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5968 - auc_2: 0.6393 - loss: 0.7059\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.57692\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6017 - auc_2: 0.6442 - loss: 0.7009 - val_accuracy: 0.4231 - val_auc_2: 0.5646 - val_loss: 0.6969 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6628 - auc_2: 0.7252 - loss: 0.6316\n",
      "Epoch 5: val_accuracy did not improve from 0.57692\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6640 - auc_2: 0.7263 - loss: 0.6302 - val_accuracy: 0.4231 - val_auc_2: 0.7231 - val_loss: 0.7050 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6691 - auc_2: 0.7449 - loss: 0.6113\n",
      "Epoch 6: val_accuracy did not improve from 0.57692\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6691 - auc_2: 0.7449 - loss: 0.6112 - val_accuracy: 0.4231 - val_auc_2: 0.7263 - val_loss: 0.7096 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6917 - auc_2: 0.7658 - loss: 0.5897\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.57692\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6917 - auc_2: 0.7655 - loss: 0.5902 - val_accuracy: 0.4231 - val_auc_2: 0.7426 - val_loss: 0.7005 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7130 - auc_2: 0.7703 - loss: 0.5912\n",
      "Epoch 8: val_accuracy did not improve from 0.57692\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7126 - auc_2: 0.7704 - loss: 0.5908 - val_accuracy: 0.4462 - val_auc_2: 0.7520 - val_loss: 0.6921 - learning_rate: 2.5000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7144 - auc_2: 0.7909 - loss: 0.5563\n",
      "Epoch 9: val_accuracy did not improve from 0.57692\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7143 - auc_2: 0.7905 - loss: 0.5568 - val_accuracy: 0.4923 - val_auc_2: 0.7508 - val_loss: 0.6867 - learning_rate: 2.5000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7314 - auc_2: 0.7780 - loss: 0.5796\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.57692\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7311 - auc_2: 0.7783 - loss: 0.5791 - val_accuracy: 0.5564 - val_auc_2: 0.7517 - val_loss: 0.6785 - learning_rate: 2.5000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7247 - auc_2: 0.7834 - loss: 0.5746\n",
      "Epoch 11: val_accuracy improved from 0.57692 to 0.63333, saving model to models/gemini_attention/fold_2_best_model.keras\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7247 - auc_2: 0.7836 - loss: 0.5743 - val_accuracy: 0.6333 - val_auc_2: 0.7505 - val_loss: 0.6505 - learning_rate: 1.2500e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7129 - auc_2: 0.7906 - loss: 0.5601\n",
      "Epoch 12: val_accuracy did not improve from 0.63333\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7132 - auc_2: 0.7908 - loss: 0.5598 - val_accuracy: 0.6333 - val_auc_2: 0.7534 - val_loss: 0.6497 - learning_rate: 1.2500e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7175 - auc_2: 0.7839 - loss: 0.5750\n",
      "Epoch 13: val_accuracy improved from 0.63333 to 0.65897, saving model to models/gemini_attention/fold_2_best_model.keras\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7180 - auc_2: 0.7848 - loss: 0.5731 - val_accuracy: 0.6590 - val_auc_2: 0.7538 - val_loss: 0.6316 - learning_rate: 1.2500e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7294 - auc_2: 0.7882 - loss: 0.5668\n",
      "Epoch 14: val_accuracy did not improve from 0.65897\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7289 - auc_2: 0.7887 - loss: 0.5659 - val_accuracy: 0.6487 - val_auc_2: 0.7537 - val_loss: 0.6513 - learning_rate: 1.2500e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m46/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7260 - auc_2: 0.8031 - loss: 0.5457\n",
      "Epoch 15: val_accuracy did not improve from 0.65897\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7265 - auc_2: 0.8033 - loss: 0.5452 - val_accuracy: 0.6538 - val_auc_2: 0.7544 - val_loss: 0.6324 - learning_rate: 1.2500e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6988 - auc_2: 0.7899 - loss: 0.5579\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 16: val_accuracy did not improve from 0.65897\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7010 - auc_2: 0.7910 - loss: 0.5565 - val_accuracy: 0.6513 - val_auc_2: 0.7540 - val_loss: 0.6473 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7408 - auc_2: 0.8140 - loss: 0.5302 \n",
      "Epoch 17: val_accuracy did not improve from 0.65897\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7396 - auc_2: 0.8129 - loss: 0.5315 - val_accuracy: 0.6487 - val_auc_2: 0.7541 - val_loss: 0.6707 - learning_rate: 6.2500e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7462 - auc_2: 0.8191 - loss: 0.5270\n",
      "Epoch 18: val_accuracy did not improve from 0.65897\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7459 - auc_2: 0.8189 - loss: 0.5272 - val_accuracy: 0.6462 - val_auc_2: 0.7547 - val_loss: 0.6815 - learning_rate: 6.2500e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7366 - auc_2: 0.8066 - loss: 0.5384\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 19: val_accuracy did not improve from 0.65897\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7367 - auc_2: 0.8070 - loss: 0.5381 - val_accuracy: 0.6333 - val_auc_2: 0.7547 - val_loss: 0.6958 - learning_rate: 6.2500e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7451 - auc_2: 0.8081 - loss: 0.5391\n",
      "Epoch 20: val_accuracy did not improve from 0.65897\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7445 - auc_2: 0.8084 - loss: 0.5387 - val_accuracy: 0.6256 - val_auc_2: 0.7543 - val_loss: 0.7203 - learning_rate: 3.1250e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7421 - auc_2: 0.7962 - loss: 0.5635\n",
      "Epoch 21: val_accuracy did not improve from 0.65897\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7427 - auc_2: 0.7977 - loss: 0.5611 - val_accuracy: 0.6308 - val_auc_2: 0.7549 - val_loss: 0.7285 - learning_rate: 3.1250e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7519 - auc_2: 0.8176 - loss: 0.5277\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 22: val_accuracy did not improve from 0.65897\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7512 - auc_2: 0.8172 - loss: 0.5281 - val_accuracy: 0.6333 - val_auc_2: 0.7552 - val_loss: 0.7207 - learning_rate: 3.1250e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7328 - auc_2: 0.8094 - loss: 0.5393\n",
      "Epoch 23: val_accuracy did not improve from 0.65897\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7323 - auc_2: 0.8092 - loss: 0.5396 - val_accuracy: 0.6333 - val_auc_2: 0.7541 - val_loss: 0.7248 - learning_rate: 1.5625e-05\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\n",
      "Training fold 4/5\n",
      "Training data shape: (1657, 768)\n",
      "Validation data shape: (390, 768)\n",
      "Epoch 1/50\n",
      "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4995 - auc_3: 0.5140 - loss: 0.8716\n",
      "Epoch 1: val_accuracy improved from -inf to 0.61026, saving model to models/gemini_attention/fold_3_best_model.keras\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5016 - auc_3: 0.5164 - loss: 0.8693 - val_accuracy: 0.6103 - val_auc_3: 0.5000 - val_loss: 0.6856 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5556 - auc_3: 0.5793 - loss: 0.7835\n",
      "Epoch 2: val_accuracy did not improve from 0.61026\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5556 - auc_3: 0.5794 - loss: 0.7834 - val_accuracy: 0.6103 - val_auc_3: 0.5000 - val_loss: 0.6881 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6122 - auc_3: 0.6598 - loss: 0.6934\n",
      "Epoch 3: val_accuracy did not improve from 0.61026\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6121 - auc_3: 0.6597 - loss: 0.6935 - val_accuracy: 0.6103 - val_auc_3: 0.5000 - val_loss: 0.6904 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6641 - auc_3: 0.7106 - loss: 0.6386 \n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.61026\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6630 - auc_3: 0.7092 - loss: 0.6408 - val_accuracy: 0.6103 - val_auc_3: 0.6507 - val_loss: 0.6906 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6703 - auc_3: 0.7260 - loss: 0.6248\n",
      "Epoch 5: val_accuracy improved from 0.61026 to 0.65385, saving model to models/gemini_attention/fold_3_best_model.keras\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6705 - auc_3: 0.7262 - loss: 0.6249 - val_accuracy: 0.6538 - val_auc_3: 0.7129 - val_loss: 0.6874 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6823 - auc_3: 0.7492 - loss: 0.6091\n",
      "Epoch 6: val_accuracy improved from 0.65385 to 0.67949, saving model to models/gemini_attention/fold_3_best_model.keras\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6822 - auc_3: 0.7489 - loss: 0.6096 - val_accuracy: 0.6795 - val_auc_3: 0.7343 - val_loss: 0.6846 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7022 - auc_3: 0.7695 - loss: 0.5907\n",
      "Epoch 7: val_accuracy improved from 0.67949 to 0.70769, saving model to models/gemini_attention/fold_3_best_model.keras\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7009 - auc_3: 0.7680 - loss: 0.5917 - val_accuracy: 0.7077 - val_auc_3: 0.7575 - val_loss: 0.6780 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6994 - auc_3: 0.7671 - loss: 0.5989\n",
      "Epoch 8: val_accuracy did not improve from 0.70769\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6995 - auc_3: 0.7674 - loss: 0.5982 - val_accuracy: 0.7026 - val_auc_3: 0.7584 - val_loss: 0.6652 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7307 - auc_3: 0.8007 - loss: 0.5466\n",
      "Epoch 9: val_accuracy did not improve from 0.70769\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7296 - auc_3: 0.7995 - loss: 0.5483 - val_accuracy: 0.6615 - val_auc_3: 0.7610 - val_loss: 0.6425 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7244 - auc_3: 0.7908 - loss: 0.5638\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.70769\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7232 - auc_3: 0.7903 - loss: 0.5639 - val_accuracy: 0.6974 - val_auc_3: 0.7589 - val_loss: 0.6274 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7247 - auc_3: 0.8032 - loss: 0.5414\n",
      "Epoch 11: val_accuracy did not improve from 0.70769\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7249 - auc_3: 0.8029 - loss: 0.5421 - val_accuracy: 0.7051 - val_auc_3: 0.7608 - val_loss: 0.6030 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7432 - auc_3: 0.8111 - loss: 0.5294\n",
      "Epoch 12: val_accuracy improved from 0.70769 to 0.71026, saving model to models/gemini_attention/fold_3_best_model.keras\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7433 - auc_3: 0.8112 - loss: 0.5295 - val_accuracy: 0.7103 - val_auc_3: 0.7604 - val_loss: 0.5860 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7592 - auc_3: 0.8256 - loss: 0.5192\n",
      "Epoch 13: val_accuracy did not improve from 0.71026\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7582 - auc_3: 0.8252 - loss: 0.5196 - val_accuracy: 0.6949 - val_auc_3: 0.7601 - val_loss: 0.5660 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7314 - auc_3: 0.8070 - loss: 0.5446\n",
      "Epoch 14: val_accuracy did not improve from 0.71026\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7315 - auc_3: 0.8072 - loss: 0.5441 - val_accuracy: 0.7026 - val_auc_3: 0.7583 - val_loss: 0.5706 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7241 - auc_3: 0.8010 - loss: 0.5479\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 15: val_accuracy did not improve from 0.71026\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7241 - auc_3: 0.8020 - loss: 0.5469 - val_accuracy: 0.7103 - val_auc_3: 0.7600 - val_loss: 0.5696 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7443 - auc_3: 0.8234 - loss: 0.5216\n",
      "Epoch 16: val_accuracy improved from 0.71026 to 0.71795, saving model to models/gemini_attention/fold_3_best_model.keras\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7442 - auc_3: 0.8232 - loss: 0.5218 - val_accuracy: 0.7179 - val_auc_3: 0.7601 - val_loss: 0.5695 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7586 - auc_3: 0.8334 - loss: 0.5094\n",
      "Epoch 17: val_accuracy did not improve from 0.71795\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7575 - auc_3: 0.8333 - loss: 0.5093 - val_accuracy: 0.7179 - val_auc_3: 0.7600 - val_loss: 0.5738 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7520 - auc_3: 0.8252 - loss: 0.5167\n",
      "Epoch 18: val_accuracy improved from 0.71795 to 0.72564, saving model to models/gemini_attention/fold_3_best_model.keras\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7522 - auc_3: 0.8250 - loss: 0.5170 - val_accuracy: 0.7256 - val_auc_3: 0.7612 - val_loss: 0.5804 - learning_rate: 1.2500e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7625 - auc_3: 0.8534 - loss: 0.4768\n",
      "Epoch 19: val_accuracy did not improve from 0.72564\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7623 - auc_3: 0.8530 - loss: 0.4773 - val_accuracy: 0.7051 - val_auc_3: 0.7612 - val_loss: 0.6195 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7453 - auc_3: 0.8188 - loss: 0.5293\n",
      "Epoch 20: val_accuracy did not improve from 0.72564\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7462 - auc_3: 0.8201 - loss: 0.5272 - val_accuracy: 0.7026 - val_auc_3: 0.7619 - val_loss: 0.6527 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7393 - auc_3: 0.8187 - loss: 0.5295\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 0.72564\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7406 - auc_3: 0.8195 - loss: 0.5286 - val_accuracy: 0.7026 - val_auc_3: 0.7618 - val_loss: 0.6396 - learning_rate: 1.2500e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7634 - auc_3: 0.8381 - loss: 0.5001\n",
      "Epoch 22: val_accuracy did not improve from 0.72564\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7633 - auc_3: 0.8379 - loss: 0.5004 - val_accuracy: 0.6974 - val_auc_3: 0.7615 - val_loss: 0.6540 - learning_rate: 6.2500e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7632 - auc_3: 0.8464 - loss: 0.4867\n",
      "Epoch 23: val_accuracy did not improve from 0.72564\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7619 - auc_3: 0.8447 - loss: 0.4891 - val_accuracy: 0.7000 - val_auc_3: 0.7624 - val_loss: 0.6614 - learning_rate: 6.2500e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7693 - auc_3: 0.8614 - loss: 0.4638\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 24: val_accuracy did not improve from 0.72564\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7679 - auc_3: 0.8594 - loss: 0.4666 - val_accuracy: 0.7051 - val_auc_3: 0.7619 - val_loss: 0.6662 - learning_rate: 6.2500e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7518 - auc_3: 0.8330 - loss: 0.5083\n",
      "Epoch 25: val_accuracy did not improve from 0.72564\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7517 - auc_3: 0.8329 - loss: 0.5085 - val_accuracy: 0.7051 - val_auc_3: 0.7628 - val_loss: 0.6659 - learning_rate: 3.1250e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7778 - auc_3: 0.8563 - loss: 0.4710\n",
      "Epoch 26: val_accuracy did not improve from 0.72564\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7776 - auc_3: 0.8561 - loss: 0.4713 - val_accuracy: 0.7026 - val_auc_3: 0.7619 - val_loss: 0.6813 - learning_rate: 3.1250e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7768 - auc_3: 0.8429 - loss: 0.4979\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 27: val_accuracy did not improve from 0.72564\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7762 - auc_3: 0.8425 - loss: 0.4984 - val_accuracy: 0.7000 - val_auc_3: 0.7617 - val_loss: 0.6836 - learning_rate: 3.1250e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7941 - auc_3: 0.8591 - loss: 0.4717\n",
      "Epoch 28: val_accuracy did not improve from 0.72564\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7927 - auc_3: 0.8582 - loss: 0.4727 - val_accuracy: 0.7026 - val_auc_3: 0.7622 - val_loss: 0.6887 - learning_rate: 1.5625e-05\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "\n",
      "Training fold 5/5\n",
      "Training data shape: (1657, 768)\n",
      "Validation data shape: (390, 768)\n",
      "Epoch 1/50\n",
      "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5161 - auc_4: 0.5308 - loss: 0.8879\n",
      "Epoch 1: val_accuracy improved from -inf to 0.51026, saving model to models/gemini_attention/fold_4_best_model.keras\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5164 - auc_4: 0.5314 - loss: 0.8880 - val_accuracy: 0.5103 - val_auc_4: 0.5000 - val_loss: 0.6944 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5256 - auc_4: 0.5520 - loss: 0.8181\n",
      "Epoch 2: val_accuracy did not improve from 0.51026\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5268 - auc_4: 0.5531 - loss: 0.8164 - val_accuracy: 0.5103 - val_auc_4: 0.5000 - val_loss: 0.6929 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m46/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5902 - auc_4: 0.6388 - loss: 0.7177\n",
      "Epoch 3: val_accuracy did not improve from 0.51026\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5926 - auc_4: 0.6395 - loss: 0.7168 - val_accuracy: 0.5103 - val_auc_4: 0.6361 - val_loss: 0.6925 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6149 - auc_4: 0.6579 - loss: 0.6925\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.51026\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6148 - auc_4: 0.6581 - loss: 0.6923 - val_accuracy: 0.4897 - val_auc_4: 0.6637 - val_loss: 0.6925 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6485 - auc_4: 0.7043 - loss: 0.6617\n",
      "Epoch 5: val_accuracy did not improve from 0.51026\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6502 - auc_4: 0.7057 - loss: 0.6603 - val_accuracy: 0.4897 - val_auc_4: 0.7591 - val_loss: 0.6928 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6692 - auc_4: 0.7324 - loss: 0.6163\n",
      "Epoch 6: val_accuracy did not improve from 0.51026\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6693 - auc_4: 0.7322 - loss: 0.6170 - val_accuracy: 0.4897 - val_auc_4: 0.7583 - val_loss: 0.6934 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6899 - auc_4: 0.7431 - loss: 0.6077\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.51026\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6899 - auc_4: 0.7435 - loss: 0.6079 - val_accuracy: 0.4923 - val_auc_4: 0.7650 - val_loss: 0.6864 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6758 - auc_4: 0.7427 - loss: 0.6169\n",
      "Epoch 8: val_accuracy improved from 0.51026 to 0.53333, saving model to models/gemini_attention/fold_4_best_model.keras\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6760 - auc_4: 0.7429 - loss: 0.6165 - val_accuracy: 0.5333 - val_auc_4: 0.7637 - val_loss: 0.6772 - learning_rate: 2.5000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7055 - auc_4: 0.7705 - loss: 0.5883\n",
      "Epoch 9: val_accuracy improved from 0.53333 to 0.62308, saving model to models/gemini_attention/fold_4_best_model.keras\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7053 - auc_4: 0.7703 - loss: 0.5884 - val_accuracy: 0.6231 - val_auc_4: 0.7654 - val_loss: 0.6609 - learning_rate: 2.5000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6735 - auc_4: 0.7438 - loss: 0.6190\n",
      "Epoch 10: val_accuracy improved from 0.62308 to 0.67692, saving model to models/gemini_attention/fold_4_best_model.keras\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6745 - auc_4: 0.7450 - loss: 0.6174 - val_accuracy: 0.6769 - val_auc_4: 0.7731 - val_loss: 0.6419 - learning_rate: 2.5000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7038 - auc_4: 0.7764 - loss: 0.5810\n",
      "Epoch 11: val_accuracy improved from 0.67692 to 0.71026, saving model to models/gemini_attention/fold_4_best_model.keras\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7037 - auc_4: 0.7763 - loss: 0.5809 - val_accuracy: 0.7103 - val_auc_4: 0.7764 - val_loss: 0.6098 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7146 - auc_4: 0.7862 - loss: 0.5622\n",
      "Epoch 12: val_accuracy did not improve from 0.71026\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7150 - auc_4: 0.7864 - loss: 0.5632 - val_accuracy: 0.7077 - val_auc_4: 0.7755 - val_loss: 0.5922 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6972 - auc_4: 0.7727 - loss: 0.5885\n",
      "Epoch 13: val_accuracy did not improve from 0.71026\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6980 - auc_4: 0.7730 - loss: 0.5876 - val_accuracy: 0.7026 - val_auc_4: 0.7762 - val_loss: 0.5761 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7245 - auc_4: 0.7998 - loss: 0.5518\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 14: val_accuracy did not improve from 0.71026\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7253 - auc_4: 0.7998 - loss: 0.5518 - val_accuracy: 0.7103 - val_auc_4: 0.7804 - val_loss: 0.5667 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7284 - auc_4: 0.8111 - loss: 0.5322\n",
      "Epoch 15: val_accuracy did not improve from 0.71026\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7274 - auc_4: 0.8097 - loss: 0.5340 - val_accuracy: 0.7103 - val_auc_4: 0.7803 - val_loss: 0.5626 - learning_rate: 1.2500e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7341 - auc_4: 0.7938 - loss: 0.5559\n",
      "Epoch 16: val_accuracy did not improve from 0.71026\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7338 - auc_4: 0.7935 - loss: 0.5561 - val_accuracy: 0.6974 - val_auc_4: 0.7792 - val_loss: 0.5699 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7207 - auc_4: 0.7981 - loss: 0.5528\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 17: val_accuracy did not improve from 0.71026\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7200 - auc_4: 0.7967 - loss: 0.5538 - val_accuracy: 0.6974 - val_auc_4: 0.7800 - val_loss: 0.5694 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7227 - auc_4: 0.7955 - loss: 0.5457\n",
      "Epoch 18: val_accuracy did not improve from 0.71026\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7227 - auc_4: 0.7953 - loss: 0.5464 - val_accuracy: 0.7051 - val_auc_4: 0.7803 - val_loss: 0.5674 - learning_rate: 6.2500e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m46/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7494 - auc_4: 0.8152 - loss: 0.5257\n",
      "Epoch 19: val_accuracy did not improve from 0.71026\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7474 - auc_4: 0.8134 - loss: 0.5280 - val_accuracy: 0.7026 - val_auc_4: 0.7803 - val_loss: 0.5674 - learning_rate: 6.2500e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7218 - auc_4: 0.7880 - loss: 0.5675\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 20: val_accuracy did not improve from 0.71026\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7224 - auc_4: 0.7895 - loss: 0.5649 - val_accuracy: 0.7026 - val_auc_4: 0.7819 - val_loss: 0.5675 - learning_rate: 6.2500e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7624 - auc_4: 0.8310 - loss: 0.5105\n",
      "Epoch 21: val_accuracy did not improve from 0.71026\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7619 - auc_4: 0.8306 - loss: 0.5111 - val_accuracy: 0.6974 - val_auc_4: 0.7822 - val_loss: 0.5682 - learning_rate: 3.1250e-05\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\n",
      "Average metrics across folds:\n",
      "val_loss: 0.6299\n",
      "val_accuracy: 0.6887\n",
      "val_auc: 0.7525\n"
     ]
    }
   ],
   "source": [
    "# Train the models\n",
    "models, histories, fold_metrics = train_ensemble_model(\n",
    "    train_df=train_df,\n",
    "    n_splits=5,\n",
    "    epochs=50,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Print average metrics across folds\n",
    "avg_metrics = {\n",
    "    metric: np.mean([fold[metric] for fold in fold_metrics])\n",
    "    for metric in fold_metrics[0].keys()\n",
    "}\n",
    "print(\"\\nAverage metrics across folds:\")\n",
    "for metric, value in avg_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# For predictions on new data:\n",
    "# predictions = predict_with_ensemble(models, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Predictions saved to final_features/gemini_attention/train_predictions.csv\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Predictions saved to final_features/gemini_attention/test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# For training data\n",
    "train_predictions = save_fold_predictions(\n",
    "    models=models,\n",
    "    data_df=train_df,\n",
    "    output_path='final_features/gemini_attention/train_predictions.csv',\n",
    "    is_train=True\n",
    ")\n",
    "\n",
    "# For test data\n",
    "test_predictions = save_fold_predictions(\n",
    "    models=models,\n",
    "    data_df=test_df,\n",
    "    output_path='final_features/gemini_attention/test_predictions.csv',\n",
    "    is_train=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
